{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3ff4bf",
   "metadata": {},
   "source": [
    "## Image Generator\n",
    "#### It systematically tries every combination of Color Palette × Pattern × Motif × Theme × Finish.\n",
    "\n",
    "### How It Works\n",
    "- Inputs: Five lists of design attributes (palettes, patterns, motifs, themes, finishes).\n",
    "- Combinations: 4 × 5 × 6 × 4 × 4 = `1920` total prompts.\n",
    "\n",
    "### Cost Considerations\n",
    "\n",
    "- Estimated cost per `1024×1024` image: `$0.04`\n",
    "- 1920 images total: `~$76.80` (rounded)\n",
    "- Cost depends on resolution and output token count.\n",
    "- Running the full set is feasible, but expensive\n",
    "\n",
    "### Time & Rate Limits\n",
    "- Default rate limit: ~50 requests per minute.\n",
    "- At 50 RPM, 1920 images take ~40 minutes.\n",
    "- script includes:\n",
    "    - Sliding-window rate limiter\n",
    "    - Exponential backoff with jitter for 429 / 5xx errors\n",
    "    - Checkpointing (skips files already generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8120e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import base64\n",
    "import itertools\n",
    "import random\n",
    "import traceback\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai import APIError, APIConnectionError, RateLimitError, InternalServerError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac3eeb",
   "metadata": {},
   "source": [
    "## Just Switch the Model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a73d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PROVIDER = \"openai\"\n",
    "# MODEL_PROVIDER = \"gemini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e83615",
   "metadata": {},
   "source": [
    "### SET the API key for the model you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIG ==========\n",
    "OPENAI_API_KEY =\"\"\n",
    "# OPENAI_API_KEY = \"\"\n",
    "OPENAI_MODEL = \"dall-e-3\"\n",
    "OPENAI_SIZE = \"1024x1024\"\n",
    "\n",
    "GEMINI_API_KEY= \" \"\n",
    "GEMINI_MODEL = \"gemini-2.0-flash-image-preview\"  # image-capable Gemini model\n",
    "GEMINI_SIZE = \"1024x1024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6219d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate limit window (tune to your plan; example: 50 requests/min)\n",
    "REQUESTS_PER_MINUTE = 50\n",
    "# Safety cap for a single run; set None to run all\n",
    "MAX_JOBS = None  # e.g., 50 for quick smoke tests\n",
    "\n",
    "# Retry policy\n",
    "MAX_RETRIES = 3\n",
    "BASE_BACKOFF_SECONDS = 2.0  # exponential backoff base\n",
    "BASE_BACKOFF = 2.0\n",
    "BACKOFF_JITTER = (0.0, 0.75)  # add random jitter to spread bursts\n",
    "\n",
    "# Output\n",
    "OUT_DIR = \"outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a966b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Import + normalize exception types so both providers hit the same handlers -----\n",
    "# Defaults in case imports fail (lets the handlers still work)\n",
    "class _FallbackRateLimitError(Exception): ...\n",
    "\n",
    "\n",
    "class _FallbackAPIError(Exception): ...\n",
    "\n",
    "\n",
    "class _FallbackAPIConnectionError(Exception): ...\n",
    "\n",
    "\n",
    "class _FallbackInternalServerError(Exception): ...\n",
    "\n",
    "\n",
    "RateLimitError = _FallbackRateLimitError\n",
    "APIError = _FallbackAPIError\n",
    "APIConnectionError = _FallbackAPIConnectionError\n",
    "InternalServerError = _FallbackInternalServerError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e0eb5",
   "metadata": {},
   "source": [
    "### Errors and Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6772a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to import OpenAI exception classes\n",
    "try:\n",
    "    from openai import RateLimitError as _OpenAIRateLimitError\n",
    "    from openai import APIError as _OpenAIAPIError\n",
    "    from openai import APIConnectionError as _OpenAIAPIConnectionError\n",
    "    from openai import InternalServerError as _OpenAIInternalServerError\n",
    "\n",
    "    RateLimitError = _OpenAIRateLimitError\n",
    "    APIError = _OpenAIAPIError\n",
    "    APIConnectionError = _OpenAIAPIConnectionError\n",
    "    InternalServerError = _OpenAIInternalServerError\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Map Gemini (google) exceptions into our normalized set\n",
    "_GEMINI_TRANSIENT_CODES = {500, 502, 503, 504}\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "\n",
    "    # google.api_core exceptions:\n",
    "    from google.api_core.exceptions import (\n",
    "        ResourceExhausted,\n",
    "        InternalServerError as GInternalServerError,\n",
    "    )\n",
    "    from google.api_core.exceptions import ServiceUnavailable, DeadlineExceeded\n",
    "    from google.api_core.exceptions import GoogleAPICallError\n",
    "\n",
    "    _HAVE_GEMINI_EXC = True\n",
    "except Exception:\n",
    "    _HAVE_GEMINI_EXC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98ffafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _raise_normalized_from_gemini(e):\n",
    "    \"\"\"\n",
    "    Convert Gemini exceptions to the same types we use for OpenAI so the shared\n",
    "    retry/limit block works IDENTICALLY.\n",
    "    \"\"\"\n",
    "    msg = str(e)\n",
    "    code = getattr(e, \"code\", None) or getattr(e, \"status\", None)\n",
    "    if _HAVE_GEMINI_EXC and isinstance(e, ResourceExhausted):\n",
    "        raise RateLimitError(msg)\n",
    "    if isinstance(e, (GInternalServerError, ServiceUnavailable, DeadlineExceeded)):\n",
    "        # transient network/server\n",
    "        err = APIError(msg)\n",
    "        setattr(err, \"status\", getattr(e, \"code\", None))\n",
    "        raise err\n",
    "    if isinstance(e, GoogleAPICallError) and code in _GEMINI_TRANSIENT_CODES:\n",
    "        err = APIError(msg)\n",
    "        setattr(err, \"status\", code)\n",
    "        raise err\n",
    "    # Unknown -> bubble up; main handler will catch as Exception\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ce00e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Rate Limiter (sliding window) -----\n",
    "# --- Rate Limiter ---\n",
    "class SlidingWindowRateLimiter:\n",
    "    \"\"\"Simple sliding-window rate limiter to enforce requests-per-minute caps.\"\"\"\n",
    "    def __init__(self, rpm: int):\n",
    "        self.capacity = max(1, rpm)\n",
    "        self.window = 60.0\n",
    "        self.events = deque()\n",
    "\n",
    "    def wait_for_slot(self):\n",
    "        now = time.time()\n",
    "        while self.events and (now - self.events[0]) > self.window:\n",
    "            self.events.popleft()\n",
    "        if len(self.events) < self.capacity:\n",
    "            self.events.append(now)\n",
    "            return\n",
    "        sleep_for = (self.events[0] + self.window) - now + 0.01\n",
    "        time.sleep(sleep_for)\n",
    "        self.events.append(time.time())\n",
    "\n",
    "\n",
    "rate_limiter = SlidingWindowRateLimiter(REQUESTS_PER_MINUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbead6ca",
   "metadata": {},
   "source": [
    "## Testing with openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9177a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_palettes_t = [\n",
    "#     \"pastel pinks\",\n",
    "#     \"jewel tones\",\n",
    "# ]\n",
    "\n",
    "# patterns_t = [\n",
    "#     \"stripes\",\n",
    "#     \"chevrons\",\n",
    "# ]\n",
    "\n",
    "# motifs_t = [\n",
    "#     \"pumpkins\",\n",
    "# ]\n",
    "\n",
    "# themes_t = [\n",
    "#     \"whimsical gothic\",\n",
    "# ]\n",
    "\n",
    "# finishes_t = [\n",
    "#     \"matte\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "979e66c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palettes = [\n",
    "    \"pastel pinks\",\n",
    "    \"jewel tones\",\n",
    "    \"metallic gold & black\",\n",
    "    \"earthy autumn shades\",\n",
    "]\n",
    "\n",
    "patterns = [\n",
    "    \"stripes\",\n",
    "    \"chevrons\",\n",
    "    \"damask\",\n",
    "    \"watercolor wash\",\n",
    "    \"geometric lattice\",\n",
    "]\n",
    "\n",
    "motifs = [\n",
    "    \"pumpkins\",\n",
    "    \"bats\",\n",
    "    \"florals\",\n",
    "    \"stars\",\n",
    "    \"waves\",\n",
    "    \"shells\",\n",
    "]\n",
    "\n",
    "themes = [\n",
    "    \"whimsical gothic\",\n",
    "    \"festive holiday sparkle\",\n",
    "    \"coastal summer\",\n",
    "    \"rustic harvest\",\n",
    "]\n",
    "\n",
    "finishes = [\n",
    "    \"matte\",\n",
    "    \"foil stamping\",\n",
    "    \"embossed texture\",\n",
    "    \"glossy lacquer\",\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"Design a premium, print-ready paper plate featuring {color_palette}, \"\n",
    "    \"with {pattern} as the base, highlighted by {motif} in a {theme} style. \"\n",
    "    \"Incorporate finishing details like {finish} for a polished, commercial look. \"\n",
    "    \"The design should balance aesthetics with festive usability and align with U.S. \"\n",
    "    \"retail holiday/gifting trends.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "07d6eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_filename(*parts: str) -> str:\n",
    "    \"\"\"Generate a safe, filesystem-friendly filename from text parts.\"\"\"\n",
    "    name = \"__\".join(parts)\n",
    "    # sanitize\n",
    "    name = name.replace(\"&\", \"and\")\n",
    "    for ch in r' <>:\"/\\|?*':\n",
    "        name = name.replace(ch, \"_\")\n",
    "    return name[:200]  # guard against super long names\n",
    "\n",
    "\n",
    "def combos() -> Iterable[Tuple[str, str, str, str, str]]:\n",
    "    \"\"\"Yield all combinations of palette, pattern, motif, theme, and finish (optionally limited).\"\"\"\n",
    "    iterable = itertools.product(color_palettes, patterns, motifs, themes, finishes)\n",
    "    if MAX_JOBS is not None:\n",
    "        # take just the first N combos for testing\n",
    "        iterable = itertools.islice(iterable, MAX_JOBS)\n",
    "    return iterable\n",
    "\n",
    "## testing with small combinations\n",
    "# def combos_test() -> Iterable[Tuple[str, str, str, str, str]]:\n",
    "#     iterable_t = itertools.product(color_palettes_t, patterns_t, motifs_t, themes_t, finishes_t)\n",
    "#     if MAX_JOBS is not None:\n",
    "#         # take just the first N combos for testing\n",
    "#         iterable = itertools.islice(iterable_t, MAX_JOBS)\n",
    "#     return iterable_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "94dc0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _call_openai(prompt: str) -> bytes:\n",
    "    \"\"\"Call OpenAI Image API with a prompt and return raw PNG bytes.\"\"\"\n",
    "    from openai import OpenAI\n",
    "\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    result = client.images.generate(\n",
    "        model=OPENAI_MODEL,\n",
    "        prompt=prompt,\n",
    "        size=OPENAI_SIZE,\n",
    "        response_format=\"b64_json\",\n",
    "    )\n",
    "    b64 = result.data[0].b64_json\n",
    "    return base64.b64decode(b64)\n",
    "\n",
    "\n",
    "def _call_gemini(prompt: str) -> bytes:\n",
    "    \"\"\"Call Gemini Image API with a prompt and return raw image bytes.\"\"\"\n",
    "    if not _HAVE_GEMINI_EXC:\n",
    "        import google.generativeai as genai  # fallback import\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL)\n",
    "    # Some SDK versions use generate_images; if you use a different method, adapt here.\n",
    "    resp = model.generate_images(prompt=prompt, size=GEMINI_SIZE)\n",
    "    # Depending on SDK version, image bytes accessor can differ:\n",
    "    # Try common attribute names in order.\n",
    "    img = resp.images[0]\n",
    "    for attr in (\"_image_bytes\", \"image_bytes\", \"bytes\", \"data\"):\n",
    "        if hasattr(img, attr):\n",
    "            return getattr(img, attr)\n",
    "    # If SDK returns base64 string:\n",
    "    if hasattr(img, \"b64_json\"):\n",
    "        return base64.b64decode(img.b64_json)\n",
    "    raise RuntimeError(\"Unable to extract image bytes from Gemini response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "344830ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_retries(call_fn, filename_stem: str) -> bytes:\n",
    "    \"\"\"Wrap image API call with rate limiting, retries, and exponential backoff.\"\"\"\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        rate_limiter.wait_for_slot()\n",
    "        try:\n",
    "            return call_fn()\n",
    "\n",
    "        except RateLimitError as e:\n",
    "            # Back off on 429\n",
    "            attempt += 1\n",
    "            if attempt > MAX_RETRIES:\n",
    "                print(\n",
    "                    f\"❌ Rate limited (exhausted retries) for: {filename_stem} -> {e}\"\n",
    "                )\n",
    "                return b\"\"\n",
    "            backoff = BASE_BACKOFF_SECONDS * (2 ** (attempt - 1)) + random.uniform(\n",
    "                *BACKOFF_JITTER\n",
    "            )\n",
    "            print(\n",
    "                f\"⏳ Rate limited (attempt {attempt}/{MAX_RETRIES}). Sleeping {backoff:.2f}s\"\n",
    "            )\n",
    "            time.sleep(backoff)\n",
    "\n",
    "        except (APIConnectionError, InternalServerError, APIError) as e:\n",
    "            # Transient network or 5xx – retry with backoff\n",
    "            status = getattr(e, \"status\", None)\n",
    "            is_transient = (status is None) or (500 <= status < 600)\n",
    "            attempt += 1\n",
    "            if (not is_transient) and (attempt > 1):\n",
    "                # Non-transient (e.g., 400) -> don't keep retrying endlessly\n",
    "                print(f\"❌ Non-retryable error for: {filename_stem} -> {e}\")\n",
    "                return b\"\"\n",
    "\n",
    "            if attempt > MAX_RETRIES:\n",
    "                print(\n",
    "                    f\"❌ API/Network error (exhausted retries) for: {filename_stem} -> {e}\"\n",
    "                )\n",
    "                return b\"\"\n",
    "\n",
    "            backoff = BASE_BACKOFF_SECONDS * (2 ** (attempt - 1)) + random.uniform(\n",
    "                *BACKOFF_JITTER\n",
    "            )\n",
    "            print(\n",
    "                f\"⏳ Transient error (attempt {attempt}/{MAX_RETRIES}). Sleeping {backoff:.2f}s\"\n",
    "            )\n",
    "            time.sleep(backoff)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Unknown error; log and continue\n",
    "            traceback.print_exc()\n",
    "            print(f\"❌ Unexpected error for: {filename_stem} -> {e}\")\n",
    "            return b\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9379fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_openai(prompt: str, filename_stem: str) -> bytes:\n",
    "    \"\"\"Generate an image with OpenAI using shared retry logic and return PNG bytes.\"\"\"\n",
    "    def _fn():\n",
    "        return _call_openai(prompt)\n",
    "\n",
    "    return generate_with_retries(_fn, filename_stem)\n",
    "\n",
    "\n",
    "def generate_gemini(prompt: str, filename_stem: str) -> bytes:\n",
    "    \"\"\"Generate an image with Gemini using shared retry logic and return PNG bytes.\"\"\"\n",
    "    def _fn():\n",
    "        try:\n",
    "            return _call_gemini(prompt)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            # Map Gemini exceptions into our normalized set *before* the shared handler sees them\n",
    "            try:\n",
    "                _raise_normalized_from_gemini(e)\n",
    "            except Exception as inner:  # re-throw mapped or original\n",
    "                raise inner\n",
    "\n",
    "    return generate_with_retries(_fn, filename_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_for_user():\n",
    "    all_combos = list(combos())\n",
    "    total_jobs = len(all_combos)\n",
    "    minutes_est = total_jobs / REQUESTS_PER_MINUTE\n",
    "    est_time = f\"~{minutes_est:.1f} minutes\"\n",
    "    est_cost = total_jobs * 0.04 if MODEL_PROVIDER == \"openai\" else \"N/A\"\n",
    "\n",
    "    print(\"=======================================\")\n",
    "    print(f\"Provider        : {MODEL_PROVIDER}\")\n",
    "    print(f\"Total jobs      : {total_jobs}\")\n",
    "    print(f\"Rate limit      : {REQUESTS_PER_MINUTE} req/min\")\n",
    "    print(f\"Estimated time  : {est_time}\")\n",
    "    if MODEL_PROVIDER == \"openai\":\n",
    "        print(f\"Estimated cost  : ${est_cost:.2f} (at $0.04 per image)\")\n",
    "    print(\"=======================================\")\n",
    "\n",
    "    print('Enter y for yes and n for No in the input box')\n",
    "\n",
    "    proceed = input(\"Proceed with generation? (y/n): \").strip().lower()\n",
    "        \n",
    "    return proceed == 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6667eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main loop: build prompts, generate images with selected provider, and save outputs.\"\"\"\n",
    "    proceed = info_for_user()\n",
    "    if not proceed:\n",
    "        print(\"❌ Aborted by user.\")\n",
    "        return\n",
    "    total = 0\n",
    "    for color, pattern, motif, theme, finish in combos():\n",
    "        stem = safe_filename(color, pattern, motif, theme, finish)\n",
    "        out_path = os.path.join(OUT_DIR, f\"{stem}.png\")\n",
    "        if os.path.exists(out_path):\n",
    "            print(f\"⏭️  Exists, skipping: {stem}\")\n",
    "            continue\n",
    "\n",
    "        prompt = PROMPT_TEMPLATE.format(\n",
    "            color_palette=color,\n",
    "            pattern=pattern,\n",
    "            motif=motif,\n",
    "            theme=theme,\n",
    "            finish=finish,\n",
    "        )\n",
    "        print(f\"→ Generating via {MODEL_PROVIDER}: {stem}\")\n",
    "\n",
    "        if MODEL_PROVIDER == \"openai\":\n",
    "            img = generate_openai(prompt, stem)\n",
    "        elif MODEL_PROVIDER == \"gemini\":\n",
    "            img = generate_gemini(prompt, stem)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown provider: {MODEL_PROVIDER}\")\n",
    "\n",
    "        if not img:\n",
    "            # generation failed but logged already\n",
    "            continue\n",
    "\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(img)\n",
    "\n",
    "        meta = os.path.join(OUT_DIR, f\"{stem}.meta.txt\")\n",
    "        with open(meta, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"provider={MODEL_PROVIDER}\\n\")\n",
    "            f.write(\n",
    "                f\"model={OPENAI_MODEL if MODEL_PROVIDER=='openai' else GEMINI_MODEL}\\n\"\n",
    "            )\n",
    "            f.write(\n",
    "                f\"size={OPENAI_SIZE if MODEL_PROVIDER=='openai' else GEMINI_SIZE}\\n\"\n",
    "            )\n",
    "            f.write(f\"prompt={prompt}\\n\")\n",
    "            f.write(f\"time={datetime.utcnow().isoformat()}Z\\n\")\n",
    "\n",
    "        print(f\"✅ Saved: {out_path}\")\n",
    "        total += 1\n",
    "\n",
    "    print(f\"\\nDone. Generated {total} images to {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98063f8",
   "metadata": {},
   "source": [
    "## preview prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "03570494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "\n",
    "def preview_prompts_filtered(\n",
    "    color: str = None,\n",
    "    pattern: str = None,\n",
    "    motif: str = None,\n",
    "    theme: str = None,\n",
    "    finish: str = None,\n",
    "    limit: int = 20,\n",
    "    width: int = 100,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate and print prompts with optional filters on any category.\n",
    "    Args:\n",
    "        color, pattern, motif, theme, finish: Filter values (exact match).\n",
    "        limit: Max number of prompts to show. Default 20. None = all.\n",
    "        width: Wrap width for readability.\n",
    "    \"\"\"\n",
    "    all_combos = list(combos())\n",
    "    filtered = []\n",
    "\n",
    "    for c, p, m, t, f in all_combos:\n",
    "        if color and c != color:\n",
    "            continue\n",
    "        if pattern and p != pattern:\n",
    "            continue\n",
    "        if motif and m != motif:\n",
    "            continue\n",
    "        if theme and t != theme:\n",
    "            continue\n",
    "        if finish and f != finish:\n",
    "            continue\n",
    "        filtered.append((c, p, m, t, f))\n",
    "\n",
    "    total = len(filtered)\n",
    "    print(\"=======================================\")\n",
    "    print(f\"Provider configured : {MODEL_PROVIDER}\")\n",
    "    print(f\"Total matches       : {total}\")\n",
    "    print(\"=======================================\")\n",
    "\n",
    "    shown = 0\n",
    "    for c, p, m, t, f in filtered:\n",
    "        prompt = PROMPT_TEMPLATE.format(\n",
    "            color_palette=c,\n",
    "            pattern=p,\n",
    "            motif=m,\n",
    "            theme=t,\n",
    "            finish=f,\n",
    "        )\n",
    "        print(f\"\\n[{shown+1}]\")\n",
    "        print(textwrap.fill(prompt, width=width))\n",
    "        print(\"-\" * width)\n",
    "\n",
    "        shown += 1\n",
    "        if limit is not None and shown >= limit:\n",
    "            break\n",
    "\n",
    "    if limit is not None and total > limit:\n",
    "        print(f\"... ({total - limit} more prompts not shown)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0723fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "Provider configured : openai\n",
      "Total matches       : 480\n",
      "=======================================\n",
      "\n",
      "[1]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by pumpkins in a whimsical gothic style. Incorporate finishing details like matte for a\n",
      "polished, commercial look. The design should balance aesthetics with festive usability and align\n",
      "with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[2]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by pumpkins in a whimsical gothic style. Incorporate finishing details like foil\n",
      "stamping for a polished, commercial look. The design should balance aesthetics with festive\n",
      "usability and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "... (478 more prompts not shown)\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# function preview_prompts_filtered(limit to see)\n",
    "# Show only prompts where color is \"jewel tones\"\n",
    "# other options ------\n",
    "# preview_prompts_filtered(motif=\"pumpkins\", limit=3)\n",
    "# ==================================\n",
    "preview_prompts_filtered(color=\"jewel tones\", limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c667a260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "Provider configured : openai\n",
      "Total matches       : 80\n",
      "=======================================\n",
      "\n",
      "[1]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a whimsical gothic style. Incorporate finishing details like matte for a\n",
      "polished, commercial look. The design should balance aesthetics with festive usability and align\n",
      "with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[2]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a whimsical gothic style. Incorporate finishing details like foil stamping\n",
      "for a polished, commercial look. The design should balance aesthetics with festive usability and\n",
      "align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[3]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a whimsical gothic style. Incorporate finishing details like embossed\n",
      "texture for a polished, commercial look. The design should balance aesthetics with festive usability\n",
      "and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[4]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a whimsical gothic style. Incorporate finishing details like glossy\n",
      "lacquer for a polished, commercial look. The design should balance aesthetics with festive usability\n",
      "and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[5]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a festive holiday sparkle style. Incorporate finishing details like matte\n",
      "for a polished, commercial look. The design should balance aesthetics with festive usability and\n",
      "align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[6]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a festive holiday sparkle style. Incorporate finishing details like foil\n",
      "stamping for a polished, commercial look. The design should balance aesthetics with festive\n",
      "usability and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[7]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a festive holiday sparkle style. Incorporate finishing details like\n",
      "embossed texture for a polished, commercial look. The design should balance aesthetics with festive\n",
      "usability and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[8]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a festive holiday sparkle style. Incorporate finishing details like glossy\n",
      "lacquer for a polished, commercial look. The design should balance aesthetics with festive usability\n",
      "and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[9]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a coastal summer style. Incorporate finishing details like matte for a\n",
      "polished, commercial look. The design should balance aesthetics with festive usability and align\n",
      "with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[10]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a coastal summer style. Incorporate finishing details like foil stamping\n",
      "for a polished, commercial look. The design should balance aesthetics with festive usability and\n",
      "align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[11]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a coastal summer style. Incorporate finishing details like embossed\n",
      "texture for a polished, commercial look. The design should balance aesthetics with festive usability\n",
      "and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[12]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a coastal summer style. Incorporate finishing details like glossy lacquer\n",
      "for a polished, commercial look. The design should balance aesthetics with festive usability and\n",
      "align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[13]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a rustic harvest style. Incorporate finishing details like matte for a\n",
      "polished, commercial look. The design should balance aesthetics with festive usability and align\n",
      "with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[14]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a rustic harvest style. Incorporate finishing details like foil stamping\n",
      "for a polished, commercial look. The design should balance aesthetics with festive usability and\n",
      "align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[15]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a rustic harvest style. Incorporate finishing details like embossed\n",
      "texture for a polished, commercial look. The design should balance aesthetics with festive usability\n",
      "and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[16]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with stripes as the base,\n",
      "highlighted by florals in a rustic harvest style. Incorporate finishing details like glossy lacquer\n",
      "for a polished, commercial look. The design should balance aesthetics with festive usability and\n",
      "align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[17]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with chevrons as the base,\n",
      "highlighted by florals in a whimsical gothic style. Incorporate finishing details like matte for a\n",
      "polished, commercial look. The design should balance aesthetics with festive usability and align\n",
      "with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[18]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with chevrons as the base,\n",
      "highlighted by florals in a whimsical gothic style. Incorporate finishing details like foil stamping\n",
      "for a polished, commercial look. The design should balance aesthetics with festive usability and\n",
      "align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[19]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with chevrons as the base,\n",
      "highlighted by florals in a whimsical gothic style. Incorporate finishing details like embossed\n",
      "texture for a polished, commercial look. The design should balance aesthetics with festive usability\n",
      "and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[20]\n",
      "Design a premium, print-ready paper plate featuring jewel tones, with chevrons as the base,\n",
      "highlighted by florals in a whimsical gothic style. Incorporate finishing details like glossy\n",
      "lacquer for a polished, commercial look. The design should balance aesthetics with festive usability\n",
      "and align with U.S. retail holiday/gifting trends.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "... (60 more prompts not shown)\n"
     ]
    }
   ],
   "source": [
    "preview_prompts_filtered(color=\"jewel tones\", motif=\"florals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1ac4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other options example\n",
    "# preview_prompts_filtered() #all at once\n",
    "# preview_prompts_filtered(motif=\"pumpkins\", limit=5)\n",
    "#preview_prompts_filtered(color=\"earthy autumn shades\", pattern=\"damask\", limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ffcd9",
   "metadata": {},
   "source": [
    "## Run this method to start generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7380317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "Provider        : openai\n",
      "Total jobs      : 1920\n",
      "Rate limit      : 50 req/min\n",
      "Estimated time  : ~38.4 minutes\n",
      "Estimated cost  : $76.80 (at $0.04 per image)\n",
      "=======================================\n",
      "Enter y for yes and n for No in the input box yellow\n",
      "→ Generating via openai: pastel_pinks__stripes__pumpkins__whimsical_gothic__matte\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m MODEL_PROVIDER == \u001b[33m\"\u001b[39m\u001b[33mgemini\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m GEMINI_API_KEY:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPlease set GEMINI_API_KEY.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m→ Generating via \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PROVIDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m MODEL_PROVIDER == \u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     img = \u001b[43mgenerate_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m MODEL_PROVIDER == \u001b[33m\"\u001b[39m\u001b[33mgemini\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     27\u001b[39m     img = generate_gemini(prompt, stem)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mgenerate_openai\u001b[39m\u001b[34m(prompt, filename_stem)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fn\u001b[39m():\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_openai(prompt)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgenerate_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_stem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mgenerate_with_retries\u001b[39m\u001b[34m(call_fn, filename_stem)\u001b[39m\n\u001b[32m      5\u001b[39m rate_limiter.wait_for_slot()\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RateLimitError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Back off on 429\u001b[39;00m\n\u001b[32m     11\u001b[39m     attempt += \u001b[32m1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_openai.<locals>._fn\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fn\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36m_call_openai\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      5\u001b[39m client = OpenAI(api_key=OPENAI_API_KEY)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m result = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOPENAI_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOPENAI_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mb64_json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m b64 = result.data[\u001b[32m0\u001b[39m].b64_json\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m base64.b64decode(b64)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/openai/resources/images.py:883\u001b[39m, in \u001b[36mImages.generate\u001b[39m\u001b[34m(self, prompt, background, model, moderation, n, output_compression, output_format, partial_images, quality, response_format, size, stream, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    856\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate\u001b[39m(\n\u001b[32m    857\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    881\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    882\u001b[39m ) -> ImagesResponse | Stream[ImageGenStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/images/generations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmoderation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoderation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_compression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpartial_images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquality\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstyle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageGenerateParamsStreaming\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageGenerateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mImagesResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageGenStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/imagine/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/ssl.py:1296\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1292\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1293\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1294\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1295\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.5/lib/python3.11/ssl.py:1169\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Minimal env checks\n",
    "    if MODEL_PROVIDER == \"openai\" and not OPENAI_API_KEY:\n",
    "        raise SystemExit(\"Please set OPENAI_API_KEY.\")\n",
    "    if MODEL_PROVIDER == \"gemini\" and not GEMINI_API_KEY:\n",
    "        raise SystemExit(\"Please set GEMINI_API_KEY.\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9babcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "dicts = {\n",
    "    \"color_palette\": \"Pastel Pinks\",\n",
    "    \"pattern\": \"Chevrons\",\n",
    "    \"motif\": \"Default\",\n",
    "    \"style\": \"Festive Holiday Sparkle\",\n",
    "    \"finish\": \"Matte\",\n",
    "}\n",
    "\n",
    "\n",
    "def any_default(d: dict) -> bool:\n",
    "    return any(isinstance(v, str) and v.lower() == \"default\" for v in d.values())\n",
    "\n",
    "print(any_default(dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5894e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    }
   ],
   "source": [
    "result = {\n",
    "    \"status\": True,\n",
    "    \"type\": \"success\",\n",
    "    \"images\": {\n",
    "        \"org\": \"original\",\n",
    "        \"low\": \"low\",\n",
    "        \"medium\": \"med\",\n",
    "        \"high\": \"high\",\n",
    "    },\n",
    "}\n",
    "\n",
    "response = result.get(\"images\")['org']\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dace74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
